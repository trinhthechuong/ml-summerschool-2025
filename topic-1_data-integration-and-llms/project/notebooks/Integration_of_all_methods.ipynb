{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from typing import Optional, List, Union\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Optional\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import requests, urllib.parse\n",
    "from langchain_core.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick via provider:model string â†’ works across providers\n",
    "llm = init_chat_model(model=\"gemini-2.5-flash\",\n",
    "                      model_provider=\"google_genai\",\n",
    "                      temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_path  = \"/Users/ilboukil/Library/CloudStorage/OneDrive-SIBSwissInstituteofBioinformatics/Trainings-cb-402/ML_summer_school_code/\"\n",
    "global_path  = \"/Users/SJp/Documents/project_local/VIB-LLM-SS/ml-summerschool-2025/topic-1_data-integration-and-llms/project/results/\"\n",
    "\n",
    "patient_id = \"MM082\"\n",
    "# Path to your JSON file (e.g., patient PKG or classification output)\n",
    "json_path = f\"{global_path}/{patient_id}.json\"\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    patient_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test without tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a biomedical-AI assistant that interprets predictions from a AI-powered predictive model for clinicians.\n",
    "You are given a JSON with some information regarding the patient and 2 drugs. In the JSON, you are given:\n",
    "- Patient ID\n",
    "- Disease type\n",
    "- For each drug, you will be given:\n",
    "    - The drug name\n",
    "    - The predicted class. This class can be one of three options: \n",
    "        - No effect if the drug is predicted as having no effect on treating the patient disease\n",
    "        - Positive response if the drug is predicted as having a positive effect on treating the patient disease\n",
    "        - Adverse effects if the drug is predicted as having a negative effect on the patient disease\n",
    "    - Each predicted class has an associated probability\n",
    "    - Each predicted class has associated features, that are responsible for the prediction. To reflect the importance of these features on the prediction we have the SHAP values. We have the top positive SHAP values and the top negative SHAP values.\n",
    "\n",
    "Taking into account this JSON and the information explained above, I want you as a smart biomedical-AI assistant to pick the best of the two drugs.\n",
    "Once you have  picked the best drug for my patient, I want you to write a report on the chosen drug, please include both positive an negative points about the drug. This should be targeted towards clinicians. \n",
    "After that, please write about the features involved in the decision making process, and look in the litterature for information about the relationship between these features and the disease the patient has. \n",
    "\"\"\"),\n",
    "    (\"human\", \"{JSON_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"JSON_input\": patient_json})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_prediction_report(BaseModel):\n",
    "    patient_ID: Optional[Union[str, int]]  # \"555-1234\", 5551234, or None\n",
    "    disease_type: str = Field(description=\"e.g., Melanoma\")\n",
    "    recomended_drug_name: str = Field(description = \"e.g., Pembrolizumab\")\n",
    "    info_on_recommended_drug: str = Field(description = \"e.g., Pembrolizumab is a PD-1 inhibitor that has demonstrated significant efficacy in advanced melanoma, improving both progression-free and overall survival. Clinically, it can induce durable responses in a subset of patients. However, its use is associated with immune-related adverse effects, including colitis, hepatitis, pneumonitis, endocrinopathies (such as hypothyroidism or hypophysitis), and less commonly severe dermatologic or neurologic toxicities. Careful monitoring and prompt management of these toxicities are essential during treatment\")\n",
    "    decision_making_process: str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=GNN_prediction_report)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract per schema:\\n{format_instructions}\"),\n",
    "    (\"human\", \"{text}\"),\n",
    "]).partial(format_instructions=format_instructions)\n",
    "\n",
    "parsing_llm = prompt | llm | parser\n",
    "\n",
    "# if `drug_text` is an AIMessage, use .content; otherwise pass the raw string\n",
    "result = parsing_llm.invoke({\"text\": response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONEncoder\n",
    "class MyEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return o.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{global_path}/MM082_results_prompt_without_tools.json\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    json.dump(MyEncoder().encode(result), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_openfda_label(ingredient):\n",
    "    \"\"\"\n",
    "    Fetches drug purpose, indications, usages, adverse reactions, warning, and dosage and administration information from the FDA API.\n",
    "\n",
    "    Args:\n",
    "        drug_name (str): The name of the drug (e.g., \"aspirin\").\n",
    "\n",
    "    Returns:\n",
    "        dict: The  response drug purpose, indications, usages, adverse reactions, warning, and dosage and administration information\n",
    "    \"\"\"\n",
    "    # Standardize ingredient name\n",
    "    ingredient = urllib.parse.quote(ingredient)\n",
    "    print(ingredient)\n",
    "    base = \"https://api.fda.gov/drug/label.json\"\n",
    "    q = f'openfda.substance_name:\"{ingredient}\"'\n",
    "    r = requests.get(base, params={\"search\": q, \"limit\": 1})\n",
    "    r.raise_for_status()\n",
    "    res = r.json().get(\"results\", [])\n",
    "    if not res:\n",
    "        q2 = f'openfda.brand_name:\"{ingredient}\"'\n",
    "        r = requests.get(base, params={\"search\": q2, \"limit\": 1})\n",
    "        r.raise_for_status()\n",
    "        res = r.json().get(\"results\", [])\n",
    "        if not res:\n",
    "            return None\n",
    "    return res[0]\n",
    "\n",
    "# item = get_openfda_label(\"ibuprofen\")\n",
    "\n",
    "# if item:\n",
    "#     for key in (\"purpose\",\"indications_and_usage\", \"adverse_reactions\", \"warnings\", \"dosage_and_administration\"):\n",
    "#         if key in item:\n",
    "#             print(f\"\\n=== {key} ===\\n{item[key][0][:800]}\")\n",
    "# else:\n",
    "#     print(\"Cannot find record on openFDA for that name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bioassistant.py\n",
    "\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "from gseapy import enrichr\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Tool: Enrichment\n",
    "# -------------------------------\n",
    "@tool\n",
    "def enrichr_query(gene_list: List[str]):\n",
    "    \"\"\"Run enrichment analysis on a list of genes using gseapy (GO Biological Process).\"\"\"\n",
    "    enr = enrichr(\n",
    "        gene_list=gene_list,\n",
    "        gene_sets='GO_Biological_Process_2021',\n",
    "        organism='Human',\n",
    "        outdir=None,\n",
    "        cutoff=0.05\n",
    "    )\n",
    "    return enr.results  # DataFrame\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# LLM setup\n",
    "# -------------------------------\n",
    "def get_llm_with_tools(model: str = \"gemini-2.5-flash\", provider: str = \"google_genai\"):\n",
    "    \"\"\"Initialize the chat model and bind the enrichment tool.\"\"\"\n",
    "    llm = init_chat_model(model=model, model_provider=provider, temperature=0.2)\n",
    "    return llm.bind_tools([enrichr_query])\n",
    "\n",
    "\n",
    "def get_prompt_chain(llm_with_tools):\n",
    "    \"\"\"Return a chain with system+human prompt bound to the LLM with tools.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful bioinformatics assistant. Use tools when needed.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    return prompt | llm_with_tools\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# SHAP â†’ Gene Sets â†’ Enrichment â†’ Summarization\n",
    "# -------------------------------\n",
    "@tool\n",
    "def analyze_patient(patient_json: Dict, patient_id: str, chain):\n",
    "    \"\"\"\n",
    "    Collect SHAP features per predicted class, run enrichment, and ask LLM to summarize.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_json : dict\n",
    "        JSON object with structure { patient_id: { \"Drugs\": {...}} }\n",
    "    patient_id : str\n",
    "        Patient ID key in patient_json\n",
    "    chain : LangChain runnable (prompt | llm_with_tools)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results_by_class : dict\n",
    "        { predicted_class: { \"positive\": enrichment_df, \"negative\": enrichment_df } }\n",
    "    \"\"\"\n",
    "    drug_keys = list(patient_json[patient_id][\"Drugs\"].keys())\n",
    "    class_features = defaultdict(lambda: {\"positive\": [], \"negative\": []})\n",
    "\n",
    "    # Step 1: Collect SHAP features by predicted class\n",
    "    for drug in drug_keys:\n",
    "        predicted_class = patient_json[patient_id][\"Drugs\"][drug][\"Predicted_Class\"]\n",
    "        pos_features = patient_json[patient_id][\"Drugs\"][drug]['SHAP']['Top_Positive']\n",
    "        neg_features = patient_json[patient_id][\"Drugs\"][drug]['SHAP']['Top_Negative']\n",
    "\n",
    "        class_features[predicted_class][\"positive\"].extend(\n",
    "            [item[\"Feature\"].split(\"_\", 1)[1] if \"_\" in item[\"Feature\"] else item[\"Feature\"]\n",
    "             for item in pos_features]\n",
    "        )\n",
    "        class_features[predicted_class][\"negative\"].extend(\n",
    "            [item[\"Feature\"].split(\"_\", 1)[1] if \"_\" in item[\"Feature\"] else item[\"Feature\"]\n",
    "             for item in neg_features]\n",
    "        )\n",
    "\n",
    "    # Step 2: Run enrichment\n",
    "    results_by_class = {}\n",
    "    for cls, feats in class_features.items():\n",
    "        results_by_class[cls] = {}\n",
    "        results_by_class[cls][\"positive\"] = (\n",
    "            enrichr_query({\"gene_list\": list(set(feats[\"positive\"]))}) if feats[\"positive\"] else None\n",
    "        )\n",
    "        results_by_class[cls][\"negative\"] = (\n",
    "            enrichr_query({\"gene_list\": list(set(feats[\"negative\"]))}) if feats[\"negative\"] else None\n",
    "        )\n",
    "\n",
    "    # Step 3: Summarize with LLM\n",
    "    summaries = {}\n",
    "    for cls, res in results_by_class.items():\n",
    "        question = f\"Predicted class: {cls}\\nSummarize functional biology or pathways of SHAP features.\\n\"\n",
    "\n",
    "        if res[\"positive\"] is not None and not res[\"positive\"].empty:\n",
    "            question += f\"\\nPositive SHAP features (supporting {cls}):\\n{res['positive'].head(10).to_string(index=False)}\\n\"\n",
    "        if res[\"negative\"] is not None and not res[\"negative\"].empty:\n",
    "            question += f\"\\nNegative SHAP features (against {cls}):\\n{res['negative'].head(10).to_string(index=False)}\\n\"\n",
    "\n",
    "        ai_msg = chain.invoke({\"question\": question})\n",
    "        summaries[cls] = ai_msg.content\n",
    "\n",
    "    return results_by_class, summaries\n",
    "\n",
    "\n",
    "# bioassistant.py (add at the bottom)\n",
    "\n",
    "import pandas as pd\n",
    "def save_patient_summary_html(patient_id: str,\n",
    "                              results_by_class: dict,\n",
    "                              summaries: dict,\n",
    "                              out_path: str = None):\n",
    "    \"\"\"\n",
    "    Save the enrichment results + LLM summaries into an HTML report.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_id : str\n",
    "        Patient identifier\n",
    "    results_by_class : dict\n",
    "        Output from analyze_patient (enrichment results)\n",
    "    summaries : dict\n",
    "        Output from analyze_patient (LLM summaries)\n",
    "    out_path : str\n",
    "        File path for the HTML file (default = f\"{patient_id}_summary.html\")\n",
    "    \"\"\"\n",
    "    if out_path is None:\n",
    "        out_path = f\"{patient_id}_summary.html\"\n",
    "\n",
    "    html_parts = [f\"<h1>Patient {patient_id} â€“ Pathway Analysis Report</h1>\"]\n",
    "\n",
    "    for cls, summary in summaries.items():\n",
    "        html_parts.append(f\"<h2>Predicted Class: {cls}</h2>\")\n",
    "        html_parts.append(f\"<p><strong>LLM Summary:</strong><br>{summary}</p>\")\n",
    "\n",
    "        # Insert enrichment tables\n",
    "        for direction in [\"positive\", \"negative\"]:\n",
    "            df = results_by_class[cls].get(direction)\n",
    "            if df is not None and not df.empty:\n",
    "                html_parts.append(f\"<h3>{direction.title()} SHAP Features Enrichment</h3>\")\n",
    "                html_parts.append(df.head(15).to_html(index=False, escape=False))\n",
    "    \n",
    "    html = \"\\n\".join(html_parts)\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(html)\n",
    "    print(f\"âœ… HTML report saved to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a biomedical-AI assistant that interprets predictions from a AI-powered predictive model for clinicians.\n",
    "You are given a JSON with some information regarding the patient and 2 drugs. In the JSON, you are given:\n",
    "- Patient ID\n",
    "- Disease type\n",
    "- For each drug, you will be given:\n",
    "    - The drug name\n",
    "    - The predicted class. This class can be one of three options: \n",
    "        - No effect if the drug is predicted as having no effect on treating the patient disease\n",
    "        - Positive response if the drug is predicted as having a positive effect on treating the patient disease\n",
    "        - Adverse effects if the drug is predicted as having a negative effect on the patient disease\n",
    "    - Each predicted class has an associated probability\n",
    "    - Each predicted class has associated features, that are responsible for the prediction. To reflect the importance of these features on the prediction we have the SHAP values. We have the top positive SHAP values and the top negative SHAP values.\n",
    "\n",
    "Taking into account this JSON and the information explained above, I want you as a smart biomedical-AI assistant to pick the best of the two drugs.\n",
    "Once you have  picked the best drug for my patient, I want you to write a report on the chosen drug, please include both positive an negative points about the drug. This should be targeted towards clinicians. You should use the tools at your disposal.\n",
    "After that, please write about the features involved in the decision making process, and use the tools at your disposal for information about the relationship between these features and the disease the patient has. You should use the tools at your disposal.\n",
    "For all tasks, tell me as much as possible.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{JSON_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([get_openfda_label, enrichr_query])\n",
    "chain = prompt | llm_with_tools | StrOutputParser()\n",
    "response = chain.invoke({\"JSON_input\": patient_json})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=GNN_prediction_report)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "prompt_formats = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract per schema:\\n{format_instructions}\"),\n",
    "    (\"human\", \"{text}\"),\n",
    "]).partial(format_instructions=format_instructions)\n",
    "\n",
    "parsing_llm = prompt_formats | llm | parser\n",
    "\n",
    "# if `drug_text` is an AIMessage, use .content; otherwise pass the raw string\n",
    "result = parsing_llm.invoke({\"text\": response})\n",
    "\n",
    "\n",
    "# save_patient_summary_html(patient_id,out_path=\"results.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return o.__dict__\n",
    "\n",
    "file_name = f\"{global_path}/MM082_results_prompt1_rep4.json\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    json.dump(MyEncoder().encode(response), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
