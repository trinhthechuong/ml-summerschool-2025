{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780c11ab-8c29-4b16-9541-66823cf9c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55bd14a-578f-49f1-8ee7-6fc04bfeb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_beta = {\n",
    "'human':\n",
    "\"MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPKVKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFGKEFTPPVQAAYQKVVAGVANALAHKYH\",\n",
    "'chimpanzee':\n",
    "\"MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTORFFESFGDLSTPDAVMGNPKVKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFGKEFTPPVQAAYQKVVAGVANALAHKYH\",\n",
    "'camel':\n",
    "\"MVHLSGDEKNAVHGLWSKVKVDEVGGEALGRLLVVYPWTRRFFESFGDLSTADAVMNNPKVKAHGSKVLNSFGDGLNHLDNLKGTYAKLSELHCDKLHVDPENFRLLGNVLVVVLARHFGKEFTPDKQAAYQKVVAGVANALAHRYH\",\n",
    "'rabbit':\n",
    "\"MVHLSSEEKSAVTALWGKVNVEEVGGEALGRLLVVYPWTQRFFESFGDLSSANAVMNNPKVKAHGKKVLAAFSEGLSHLDNLKGTFAKLSELHCDKLHVDPENFRLLGNVLVIVLSHHFGKEFTPQVQAAYQKVVAGVANALAHKYH\",\n",
    "'pig':\n",
    "\"MVHLSAEEKEAVLGLWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSNADAVMGNPKVKAHGKKVLQSFSDGLKHLDNLKGTFAKLSELHCDQLHVDPENFRLLGNVIVVVLARRLGHDFNPNVQAAFQKVVAGVANALAHKYH\",\n",
    "'horse':\n",
    "\"*VQLSGEEKAAVLALWDKVNEEEVGGEALGRLLVVYPWTQRFFDSFGDLSNPGAVMGNPKVKAHGKKVLHSFGEGVHHLDNLKGTFAALSELHCDKLHVDPENFRLLGNVLVVVLARHFGKDFTPELQASYQKVVAGVANALAHKYH\",\n",
    "'bovine':\n",
    "\"M**LTAEEKAAVTAFWGKVKVDEVGGEALGRLLVVYPWTQRFFESFGDLSTADAVMNNPKVKAHGKKVLDSFSNGMKHLDDLKGTFAALSELHCDKLHVDPENFKLLGNVLVVVLARNFGKEFTPVLQADFQKVVAGVANALAHRYH\",\n",
    "'sheep':\n",
    "\"M**LTAEEKAAVTGFWGKVKVDEVGAEALGRLLVVYPWTQRFFEHFGDLSNADAVMNNPKVKAHGKKVLDSFSNGMKHLDDLKGTFAQLSELHCDKLHVDPENFRLLGNVLVVVLARHHGNEFTPVLQADFQKVVAGVANALAHKYH\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3482d8-94c3-4ca4-b7d6-5859c2da4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_protbert_embeddings(sequences, model_name=\"Rostlab/prot_bert\"):\n",
    "    \"\"\"\n",
    "    Get embeddings from ProtBERT for a list of protein sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - sequences: list of protein sequences\n",
    "    - model_name: ProtBERT model name\n",
    "    \n",
    "    Returns:\n",
    "    - embeddings: numpy array of embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        # Add spaces between amino acids (ProtBERT format)\n",
    "        spaced_seq = ' '.join(list(seq))\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(spaced_seq, return_tensors='pt', padding=True, truncation=True)\n",
    "        \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Use [CLS] token embedding (first token)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            embeddings.append(cls_embedding[0])\n",
    "    \n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646f3d9a-1593-4e52-8867-9d6e0395c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_protbert_embeddings(embeddings, labels=None, method='pca', figsize=(6, 4)):\n",
    "    \"\"\"\n",
    "    Visualize protein embeddings from ProtBERT using dimensionality reduction\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings: numpy array of shape (n_proteins, embedding_dim)\n",
    "    - labels: list of protein names/categories (optional)\n",
    "    - method: 'pca', 'tsne', or 'umap'\n",
    "    - figsize: figure size tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dimensionality reduction\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "        embedding_2d = reducer.fit_transform(embeddings)\n",
    "        title = f'ProtBERT Embeddings - PCA\\n(Explained variance: {reducer.explained_variance_ratio_.sum():.3f})'\n",
    "    \n",
    "    elif method == 'tsne':\n",
    "        perp = 30 if 30 < len(labels) else (len(labels)-1)\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=perp)\n",
    "        embedding_2d = reducer.fit_transform(embeddings)\n",
    "        title = 'ProtBERT Embeddings - t-SNE'\n",
    "    \n",
    "    elif method == 'umap':\n",
    "        reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "        embedding_2d = reducer.fit_transform(embeddings)\n",
    "        title = 'ProtBERT Embeddings - UMAP'\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if labels is None:\n",
    "        plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], alpha=0.7, s=50)\n",
    "    else:\n",
    "        # Color by labels if provided\n",
    "        unique_labels = list(set(labels))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for i, label in enumerate(unique_labels):\n",
    "            mask = np.array(labels) == label\n",
    "            plt.scatter(embedding_2d[mask, 0], embedding_2d[mask, 1], \n",
    "                       c=[colors[i]], label=label, alpha=0.7, s=50)\n",
    "        \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.xlabel(f'{method.upper()} Component 1', fontsize=12)\n",
    "    plt.ylabel(f'{method.upper()} Component 2', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad99c76-05a7-4424-b4e3-093f6fb0a4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f596cca8cf4e13b5d5d6b8ee1bced7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a3a0d19c7b42ebaf5739873c411bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/361 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f422d4b64bc481891367898b59e1dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a26492198934f15a95fa4bf785732bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b4eae057a84cc7ae3c7f693eb7578b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_sequences = list(hemoglobin_beta.values())\n",
    "sample_labels = list(hemoglobin_beta.keys())\n",
    "\n",
    "embeddings = get_protbert_embeddings(sample_sequences)\n",
    "\n",
    "# Visualize with different methods\n",
    "for method in ['pca', 'tsne', 'umap']:\n",
    "    visualize_protbert_embeddings(embeddings, sample_labels, method=method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
