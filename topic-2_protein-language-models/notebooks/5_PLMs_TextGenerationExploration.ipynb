{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddb2205-9c18-412b-822f-7b457a82dfdf",
   "metadata": {},
   "source": [
    "# Text-based Conditional Sequence Generation\n",
    "\n",
    "Here, we explore a generative model that is based on a text LLM specialised by fine tuning to understand protein sequences. \n",
    "\n",
    "This model, described in the paper [Energy Efficient Protein Language Models: Leveraging Small Language Models with LoRA for Controllable Protein Generation](https://arxiv.org/abs/2411.05966), starts from a pre-trained text LLM and then gives it additional protein-sequence fine-tuning. As a result the model learns how to generate protein sequences and can be conditioned on one of the ten class names that the model knows about. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d897cf31-44d1-48de-a33a-43b9ed4455ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a5a1a-a768-4b36-9008-9c9b0ea0ec6d",
   "metadata": {},
   "source": [
    "### Unconditional generation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3f505-5e3a-4694-956c-c5544759b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=\"Esperanto/Protein-Phi-3-mini\", tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True) )\n",
    "\n",
    "sequences = generator(\"Seq=<\",temperature=0.2,\n",
    "    top_k=40,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=30,  # Length of the generated protein sequence\n",
    "    num_return_sequences=5)  # Number of generated protein sequences\n",
    "\n",
    "for sequence in sequences:\n",
    "    print(sequence['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42bd14f-5254-4475-af14-ddbc3e9b4eb1",
   "metadata": {},
   "source": [
    "### Conditional generation example\n",
    "\n",
    "Note the specified conditional text `[Generate Ligase enzyme protein]`. \n",
    "\n",
    "The options that the model was trained on are: \n",
    "- SAM-MT \n",
    "- TPHD \n",
    "- TRX \n",
    "- CheY \n",
    "- Ligase \n",
    "- Hydrolase \n",
    "- Lyase \n",
    "- Oxidoreductase \n",
    "- Transferase \n",
    "- Isomerase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db49b9-5d65-4e99-9bc4-840e094a2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=\"Esperanto/Protein-Phi-3-mini\", tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True))\n",
    "\n",
    "sequences = generator(\"[Generate Ligase enzyme protein] Seq=<\",temperature=0.2,\n",
    "    top_k=40,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=30,  # Length\n",
    "    num_return_sequences=5)  # Number\n",
    "\n",
    "for sequence in sequences:\n",
    "    print(sequence['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c6ccf-c247-46df-9537-e695c7932a4c",
   "metadata": {},
   "source": [
    "### ProGen2 - a family of generative models for protein sequence generation\n",
    "\n",
    "This family of models is described in the paper [ProGen2: Exploring the boundaries of protein language models](https://www.cell.com/cell-systems/fulltext/S2405-4712(23)00272-7). They train models of different sizes. We use the 'small' version which uses less resources but then gives less diverse sequences. \n",
    "\n",
    "This model can do: \n",
    "- Unconditional Generation - Provide  \"1\" as the prompt for random proteins\n",
    "- Family-Conditioned Generation - Use different numeric IDs (1, 2, 3, etc.) to condition on protein families\n",
    "- Sequence Completion - Provide partial sequences and let the model complete them e.g. provide the prompt prompt `\"1MEVVIVTGMSGAGK\"`\n",
    "- Temperature Control - Adjust randomness vs. conservativeness (e.g. add parameter `temperature=0.7` to the `pipe` call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adb8b8-294f-4230-a12d-cfcd8d460d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"hugohrban/progen2-small\", trust_remote_code=True)\n",
    "\n",
    "pipe(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c71930-4601-40c4-86c6-a7bcac99a547",
   "metadata": {},
   "source": [
    "## Bonus Exercise\n",
    "\n",
    "###Â What do state of the art natural language models know about proteins based on their sequences? \n",
    "\n",
    "Try the following prompt in some of the state of the art natural language models (e.g. claude.ai, chat.openai.com, chat.deepseek.com)\n",
    "\n",
    "```\n",
    "Can you describe this protein? MSTAGKVIKCKAAVLWELKKPFSIEEVEVAPPKAHEVRIKMVAAGICRSDEHVVSGNLVTPLPVILGHEAAGIVESVGEGVTTVKPGDKVIPLFTPQCGKCRICKNPESNYCLKNDLGNPRGTLQDGTRRFTCSGKPIHHFVGVSTFSQYTVVDENAVAKIDAASPLEKVCLIGCGFSTGYGSAVKVAKVTPGSTCAVFGLGGVGLSVVMGCKAAGAARIIAVDINKDKFAKAKELGATECINPQDYKKPIQEVLKEMTDGGVDFSFEVIGRLDTMMASLLCCHEACGTSVIVGVPPDSQNLSINPMLLLTGRTWKGAIFGGFKSKESVPKLVADFMAKKFSLDALITNILPFEKINEGFDLLRSGKSIRTVLTF\n",
    "```\n",
    "\n",
    "The protein is P00326 - [alcohol dehydrogenase](https://www.uniprot.org/uniprotkb/P00326/entry#sequences). \n",
    "\n",
    "How accurate or relevant are the descriptions in the different models? Now try some of your own favourite protein sequences. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e35ac0-e23b-41b5-9676-274ebce0b211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
